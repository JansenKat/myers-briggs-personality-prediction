{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (MBTI) Myers-Briggs Personality Type Prediction\n",
    "\n",
    "* Extroversion vs. Introversion\n",
    "    * I - 0\n",
    "    * E - 1 \n",
    "    \n",
    "* Sensing vs. Intuition \n",
    "    * N - 0 \n",
    "    * S - 1\n",
    "    \n",
    "* Thinking vs. Feeling\n",
    "    * F - 0\n",
    "    * T - 1\n",
    "    \n",
    "* Judging vs. Perceiving\n",
    "    * P - 0\n",
    "    * J - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# importing dependencies here\\nimport numpy as np\\nimport pandas as pd\\n\\n# visualizations\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# data stratifying and splitting\\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\\nfrom sklearn.model_selection import train_test_split\\n\\n# algorithms/models\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nfrom imblearn.pipeline import make_pipeline as imb_make_pipeline\\nfrom imblearn.under_sampling import RandomUnderSampler\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.over_sampling import ADASYN\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.metrics import confusion_matrix\\n\\n# model performance evaluation and selection\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    accuracy_score,\\n    roc_auc_score,\\n)\\n\\n# performance check\\nimport time\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# saving the model\\nfrom joblib import dump\\n\\n\\n# code formatter\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# importing dependencies here\\nimport numpy as np\\nimport pandas as pd\\n\\n# visualizations\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# data stratifying and splitting\\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\\nfrom sklearn.model_selection import train_test_split\\n\\n# algorithms/models\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nfrom imblearn.pipeline import make_pipeline as imb_make_pipeline\\nfrom imblearn.under_sampling import RandomUnderSampler\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.over_sampling import ADASYN\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.metrics import confusion_matrix\\n\\n# model performance evaluation and selection\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    accuracy_score,\\n    roc_auc_score,\\n)\\n\\n# performance check\\nimport time\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# saving the model\\nfrom joblib import dump\\n\\n\\n# code formatter\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing dependencies here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data stratifying and splitting\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# algorithms/models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# model performance evaluation and selection\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# performance check\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# saving the model\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# code formatter\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# reading the final datasets\\npersonality_data = pd.read_csv(\\\"data_ekta/clean_data_3.csv\\\")\\ntfidf_vectorized_data = pd.read_csv(\\\"data_ekta/tfidf_vectorized_data.csv\\\")\\ncount_vectorized_data = pd.read_csv(\\\"data_ekta/count_vectorized_data.csv\\\")\";\n",
       "                var nbb_formatted_code = \"# reading the final datasets\\npersonality_data = pd.read_csv(\\\"data_ekta/clean_data_3.csv\\\")\\ntfidf_vectorized_data = pd.read_csv(\\\"data_ekta/tfidf_vectorized_data.csv\\\")\\ncount_vectorized_data = pd.read_csv(\\\"data_ekta/count_vectorized_data.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading the final datasets\n",
    "personality_data = pd.read_csv(\"data_ekta/clean_data_3.csv\")\n",
    "tfidf_vectorized_data = pd.read_csv(\"data_ekta/tfidf_vectorized_data.csv\")\n",
    "count_vectorized_data = pd.read_csv(\"data_ekta/count_vectorized_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_Extrovert</th>\n",
       "      <th>is_Sensing</th>\n",
       "      <th>is_Thinking</th>\n",
       "      <th>is_Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>avg_word_ct</th>\n",
       "      <th>post_length_var</th>\n",
       "      <th>med_char</th>\n",
       "      <th>med_word</th>\n",
       "      <th>upper</th>\n",
       "      <th>link_count</th>\n",
       "      <th>ellipses</th>\n",
       "      <th>img_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>youtube    moment  youtube  sportscenter top t...</td>\n",
       "      <td>0.997599</td>\n",
       "      <td>0.352861</td>\n",
       "      <td>0.292958</td>\n",
       "      <td>...</td>\n",
       "      <td>578</td>\n",
       "      <td>376</td>\n",
       "      <td>11.56</td>\n",
       "      <td>135.2900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>im finding lack post alarming sex boring posit...</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.361035</td>\n",
       "      <td>0.349296</td>\n",
       "      <td>...</td>\n",
       "      <td>1194</td>\n",
       "      <td>596</td>\n",
       "      <td>23.88</td>\n",
       "      <td>187.4756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_Extrovert  is_Sensing  is_Thinking  is_Judging  \\\n",
       "0  INFJ             0           0            0           1   \n",
       "1  ENTP             1           0            1           0   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1  'I'm finding the lack of me in these posts ver...   \n",
       "\n",
       "                                         clean_posts  compound_sentiment  \\\n",
       "0  youtube    moment  youtube  sportscenter top t...            0.997599   \n",
       "1  im finding lack post alarming sex boring posit...            0.999250   \n",
       "\n",
       "   pos_sentiment  neg_sentiment  ...  word_count unique_words avg_word_ct  \\\n",
       "0       0.352861       0.292958  ...         578          376       11.56   \n",
       "1       0.361035       0.349296  ...        1194          596       23.88   \n",
       "\n",
       "   post_length_var  med_char  med_word  upper  link_count  ellipses  img_count  \n",
       "0         135.2900       1.0       1.0     13          24         7          7  \n",
       "1         187.4756       1.0       1.0     82          10         0          8  \n",
       "\n",
       "[2 rows x 141 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# checking counts dataset\\npersonality_data.head(2)\";\n",
       "                var nbb_formatted_code = \"# checking counts dataset\\npersonality_data.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking counts dataset\n",
    "personality_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030203</td>\n",
       "      <td>0.582080</td>\n",
       "      <td>0.051687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103384</td>\n",
       "      <td>0.031132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability      able  absolute  absolutely  abstract  accept  according  \\\n",
       "0      0.0  0.000000       0.0         0.0       0.0     0.0        0.0   \n",
       "1      0.0  0.038337       0.0         0.0       0.0     0.0        0.0   \n",
       "\n",
       "   account  accurate  across  ...  yesterday  yet  youd  youll  young  \\\n",
       "0      0.0       0.0     0.0  ...        0.0  0.0   0.0    0.0    0.0   \n",
       "1      0.0       0.0     0.0  ...        0.0  0.0   0.0    0.0    0.0   \n",
       "\n",
       "   younger     youre   youtube     youve  yup  \n",
       "0      0.0  0.030203  0.582080  0.051687  0.0  \n",
       "1      0.0  0.103384  0.031132  0.000000  0.0  \n",
       "\n",
       "[2 rows x 1469 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# checking TF-IDF vectorized dataset\\ntfidf_vectorized_data.head(2)\";\n",
       "                var nbb_formatted_code = \"# checking TF-IDF vectorized dataset\\ntfidf_vectorized_data.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking TF-IDF vectorized dataset\n",
    "tfidf_vectorized_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  absolute  absolutely  abstract  accept  according  account  \\\n",
       "0        0     0         0           0         0       0          0        0   \n",
       "1        0     1         0           0         0       0          0        0   \n",
       "\n",
       "   accurate  act  ...  yes  yesterday  youd  youll  young  younger  youre  \\\n",
       "0         0    0  ...    0          0     0      0      0        0      1   \n",
       "1         0    0  ...    0          0     0      0      0        0      4   \n",
       "\n",
       "   youtube  youve  yup  \n",
       "0       16      1    0  \n",
       "1        1      0    0  \n",
       "\n",
       "[2 rows x 1353 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# checking Count vectorized dataset\\ncount_vectorized_data.head(2)\";\n",
       "                var nbb_formatted_code = \"# checking Count vectorized dataset\\ncount_vectorized_data.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking Count vectorized dataset\n",
    "count_vectorized_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 141)\n",
      "(8675, 1469)\n",
      "(8675, 1353)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# checking the number of rows and columns in each dataset\\nprint(personality_data.shape)\\nprint(tfidf_vectorized_data.shape)\\nprint(count_vectorized_data.shape)\";\n",
       "                var nbb_formatted_code = \"# checking the number of rows and columns in each dataset\\nprint(personality_data.shape)\\nprint(tfidf_vectorized_data.shape)\\nprint(count_vectorized_data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the number of rows and columns in each dataset\n",
    "print(personality_data.shape)\n",
    "print(tfidf_vectorized_data.shape)\n",
    "print(count_vectorized_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X = personality_data[\\n    [\\n        \\\"compound_sentiment\\\",\\n        \\\"S_ADJ_med\\\",\\n        \\\"S_ADJ_std\\\",\\n        \\\"S_ADP_med\\\",\\n        \\\"S_ADP_std\\\",\\n        \\\"S_ADV_med\\\",\\n        \\\"S_ADV_std\\\",\\n        \\\"S_CONJ_med\\\",\\n        \\\"S_CONJ_std\\\",\\n        \\\"S_DET_med\\\",\\n        \\\"S_DET_std\\\",\\n        \\\"S_NOUN_med\\\",\\n        \\\"S_NOUN_std\\\",\\n        \\\"S_NUM_med\\\",\\n        \\\"S_NUM_std\\\",\\n        \\\"S_PRT_med\\\",\\n        \\\"S_PRT_std\\\",\\n        \\\"S_PRON_med\\\",\\n        \\\"S_PRON_std\\\",\\n        \\\"S_VERB_med\\\",\\n        \\\"S_VERB_std\\\",\\n        \\\"qm\\\",\\n        \\\"em\\\",\\n        \\\"colons\\\",\\n        \\\"emojis\\\",\\n        \\\"word_count\\\",\\n        \\\"unique_words\\\",\\n        \\\"avg_word_ct\\\",\\n        \\\"post_length_var\\\",\\n        \\\"med_char\\\",\\n        \\\"med_word\\\",\\n        \\\"upper\\\",\\n        \\\"link_count\\\",\\n        \\\"ellipses\\\",\\n        \\\"img_count\\\",\\n    ]\\n]\";\n",
       "                var nbb_formatted_code = \"X = personality_data[\\n    [\\n        \\\"compound_sentiment\\\",\\n        \\\"S_ADJ_med\\\",\\n        \\\"S_ADJ_std\\\",\\n        \\\"S_ADP_med\\\",\\n        \\\"S_ADP_std\\\",\\n        \\\"S_ADV_med\\\",\\n        \\\"S_ADV_std\\\",\\n        \\\"S_CONJ_med\\\",\\n        \\\"S_CONJ_std\\\",\\n        \\\"S_DET_med\\\",\\n        \\\"S_DET_std\\\",\\n        \\\"S_NOUN_med\\\",\\n        \\\"S_NOUN_std\\\",\\n        \\\"S_NUM_med\\\",\\n        \\\"S_NUM_std\\\",\\n        \\\"S_PRT_med\\\",\\n        \\\"S_PRT_std\\\",\\n        \\\"S_PRON_med\\\",\\n        \\\"S_PRON_std\\\",\\n        \\\"S_VERB_med\\\",\\n        \\\"S_VERB_std\\\",\\n        \\\"qm\\\",\\n        \\\"em\\\",\\n        \\\"colons\\\",\\n        \\\"emojis\\\",\\n        \\\"word_count\\\",\\n        \\\"unique_words\\\",\\n        \\\"avg_word_ct\\\",\\n        \\\"post_length_var\\\",\\n        \\\"med_char\\\",\\n        \\\"med_word\\\",\\n        \\\"upper\\\",\\n        \\\"link_count\\\",\\n        \\\"ellipses\\\",\\n        \\\"img_count\\\",\\n    ]\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = personality_data[\n",
    "    [\n",
    "        \"compound_sentiment\",\n",
    "        \"S_ADJ_med\",\n",
    "        \"S_ADJ_std\",\n",
    "        \"S_ADP_med\",\n",
    "        \"S_ADP_std\",\n",
    "        \"S_ADV_med\",\n",
    "        \"S_ADV_std\",\n",
    "        \"S_CONJ_med\",\n",
    "        \"S_CONJ_std\",\n",
    "        \"S_DET_med\",\n",
    "        \"S_DET_std\",\n",
    "        \"S_NOUN_med\",\n",
    "        \"S_NOUN_std\",\n",
    "        \"S_NUM_med\",\n",
    "        \"S_NUM_std\",\n",
    "        \"S_PRT_med\",\n",
    "        \"S_PRT_std\",\n",
    "        \"S_PRON_med\",\n",
    "        \"S_PRON_std\",\n",
    "        \"S_VERB_med\",\n",
    "        \"S_VERB_std\",\n",
    "        \"qm\",\n",
    "        \"em\",\n",
    "        \"colons\",\n",
    "        \"emojis\",\n",
    "        \"word_count\",\n",
    "        \"unique_words\",\n",
    "        \"avg_word_ct\",\n",
    "        \"post_length_var\",\n",
    "        \"med_char\",\n",
    "        \"med_word\",\n",
    "        \"upper\",\n",
    "        \"link_count\",\n",
    "        \"ellipses\",\n",
    "        \"img_count\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting predictors and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 1504)\n",
      "(8675, 1388)\n",
      "(8675, 4)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# combining counts, sentiment score and TF-IDF vectorized data\\n# X_tf = pd.concat([personality_data.iloc[:, 8:20], tfidf_vectorized_data], axis=1)\\nX_tf = pd.concat([X, tfidf_vectorized_data], axis=1)\\n\\n# combining counts, sentiment score and Count vectorized data\\n# X_ct = pd.concat([personality_data.iloc[:, 8:20], count_vectorized_data], axis=1)\\nX_ct = pd.concat([X, count_vectorized_data], axis=1)\\n\\n# since it is a multiclass problem with class imbalance, we will use 4 type variables as predictors instead of 1 \\\"type\\\" col\\ny = personality_data.iloc[:, 1:5]\\n# y = target_y\\n\\nprint(X_tf.shape)\\nprint(X_ct.shape)\\nprint(y.shape)\";\n",
       "                var nbb_formatted_code = \"# combining counts, sentiment score and TF-IDF vectorized data\\n# X_tf = pd.concat([personality_data.iloc[:, 8:20], tfidf_vectorized_data], axis=1)\\nX_tf = pd.concat([X, tfidf_vectorized_data], axis=1)\\n\\n# combining counts, sentiment score and Count vectorized data\\n# X_ct = pd.concat([personality_data.iloc[:, 8:20], count_vectorized_data], axis=1)\\nX_ct = pd.concat([X, count_vectorized_data], axis=1)\\n\\n# since it is a multiclass problem with class imbalance, we will use 4 type variables as predictors instead of 1 \\\"type\\\" col\\ny = personality_data.iloc[:, 1:5]\\n# y = target_y\\n\\nprint(X_tf.shape)\\nprint(X_ct.shape)\\nprint(y.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combining counts, sentiment score and TF-IDF vectorized data\n",
    "# X_tf = pd.concat([personality_data.iloc[:, 8:20], tfidf_vectorized_data], axis=1)\n",
    "X_tf = pd.concat([X, tfidf_vectorized_data], axis=1)\n",
    "\n",
    "# combining counts, sentiment score and Count vectorized data\n",
    "# X_ct = pd.concat([personality_data.iloc[:, 8:20], count_vectorized_data], axis=1)\n",
    "X_ct = pd.concat([X, count_vectorized_data], axis=1)\n",
    "\n",
    "# since it is a multiclass problem with class imbalance, we will use 4 type variables as predictors instead of 1 \"type\" col\n",
    "y = personality_data.iloc[:, 1:5]\n",
    "# y = target_y\n",
    "\n",
    "print(X_tf.shape)\n",
    "print(X_ct.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def create_model(model, X, target, nsplits):\\n\\n    mbti_type = {\\n        \\\"is_Extrovert\\\": \\\"Extrovert vs Introvert\\\",\\n        \\\"is_Sensing\\\": \\\"Sensing vs Intuition\\\",\\n        \\\"is_Thinking\\\": \\\"Thinking vs Feeling\\\",\\n        \\\"is_Judging\\\": \\\"Judging vs Perceiving\\\",\\n    }\\n\\n    trans_list = [\\n        {0: \\\"I\\\", 1: \\\"E\\\"},\\n        {0: \\\"N\\\", 1: \\\"S\\\"},\\n        {0: \\\"F\\\", 1: \\\"T\\\"},\\n        {0: \\\"J\\\", 1: \\\"P\\\"},\\n    ]\\n\\n    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=1)\\n\\n    # to time the individual model run time\\n    t = time.time()\\n\\n    predictions = []\\n\\n    for col in target.columns:\\n\\n        print(f\\\"\\\\n{mbti_type[col]}\\\")\\n        y = target[col]\\n        auc_list, acc_list, f1_list = [], [], []\\n\\n        #         X_train, X_test, y_train, y_test = train_test_split(\\n        #             X, target[col], random_state=0, test_size=0.20, stratify=target[col]\\n        #         )\\n\\n        for train_index, test_index in kfold.split(X, y):\\n\\n            X_train, X_test, y_train, y_test = (\\n                X.iloc[train_index],\\n                X.iloc[test_index],\\n                y[train_index],\\n                y[test_index],\\n            )\\n\\n            model.fit(X_train, y_train)\\n\\n            y_pred = model.predict(X_test)\\n            #         predictions.append(y_pred)\\n            #             print(\\\"RESULT\\\", y_pred)\\n\\n            preds = model.predict_proba(X_test)[\\n                :, 1\\n            ]  # returns the probablity of class 1\\n            auc = roc_auc_score(y_test, preds)\\n            acc = accuracy_score(y_test, preds.round())\\n            f1 = f1_score(y_test, preds.round())\\n\\n            #         auc = roc_auc_score(y_test, y_pred)\\n            #         acc = accuracy_score(y_test, y_pred)\\n            #         f1 = f1_score(y_test, y_pred)\\n\\n            auc_list.append(auc)\\n            acc_list.append(acc)\\n            f1_list.append(f1)\\n\\n        #         print(f\\\"Avg AUC: {auc:.2f}, Avg Accuracy: {acc:.2f}, Avg F1: {f1:.2f}\\\")\\n        print(\\n            f\\\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\\\"\\n        )\\n        print(classification_report(y_test, y_pred))\\n\\n    #         print(\\\"Cross val score:\\\", cross_val_score(model, X, y[col], cv=5, scoring=\\\"f1\\\"))\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")\";\n",
       "                var nbb_formatted_code = \"def create_model(model, X, target, nsplits):\\n\\n    mbti_type = {\\n        \\\"is_Extrovert\\\": \\\"Extrovert vs Introvert\\\",\\n        \\\"is_Sensing\\\": \\\"Sensing vs Intuition\\\",\\n        \\\"is_Thinking\\\": \\\"Thinking vs Feeling\\\",\\n        \\\"is_Judging\\\": \\\"Judging vs Perceiving\\\",\\n    }\\n\\n    trans_list = [\\n        {0: \\\"I\\\", 1: \\\"E\\\"},\\n        {0: \\\"N\\\", 1: \\\"S\\\"},\\n        {0: \\\"F\\\", 1: \\\"T\\\"},\\n        {0: \\\"J\\\", 1: \\\"P\\\"},\\n    ]\\n\\n    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=1)\\n\\n    # to time the individual model run time\\n    t = time.time()\\n\\n    predictions = []\\n\\n    for col in target.columns:\\n\\n        print(f\\\"\\\\n{mbti_type[col]}\\\")\\n        y = target[col]\\n        auc_list, acc_list, f1_list = [], [], []\\n\\n        #         X_train, X_test, y_train, y_test = train_test_split(\\n        #             X, target[col], random_state=0, test_size=0.20, stratify=target[col]\\n        #         )\\n\\n        for train_index, test_index in kfold.split(X, y):\\n\\n            X_train, X_test, y_train, y_test = (\\n                X.iloc[train_index],\\n                X.iloc[test_index],\\n                y[train_index],\\n                y[test_index],\\n            )\\n\\n            model.fit(X_train, y_train)\\n\\n            y_pred = model.predict(X_test)\\n            #         predictions.append(y_pred)\\n            #             print(\\\"RESULT\\\", y_pred)\\n\\n            preds = model.predict_proba(X_test)[\\n                :, 1\\n            ]  # returns the probablity of class 1\\n            auc = roc_auc_score(y_test, preds)\\n            acc = accuracy_score(y_test, preds.round())\\n            f1 = f1_score(y_test, preds.round())\\n\\n            #         auc = roc_auc_score(y_test, y_pred)\\n            #         acc = accuracy_score(y_test, y_pred)\\n            #         f1 = f1_score(y_test, y_pred)\\n\\n            auc_list.append(auc)\\n            acc_list.append(acc)\\n            f1_list.append(f1)\\n\\n        #         print(f\\\"Avg AUC: {auc:.2f}, Avg Accuracy: {acc:.2f}, Avg F1: {f1:.2f}\\\")\\n        print(\\n            f\\\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\\\"\\n        )\\n        print(classification_report(y_test, y_pred))\\n\\n    #         print(\\\"Cross val score:\\\", cross_val_score(model, X, y[col], cv=5, scoring=\\\"f1\\\"))\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(model, X, target, nsplits):\n",
    "\n",
    "    mbti_type = {\n",
    "        \"is_Extrovert\": \"Extrovert vs Introvert\",\n",
    "        \"is_Sensing\": \"Sensing vs Intuition\",\n",
    "        \"is_Thinking\": \"Thinking vs Feeling\",\n",
    "        \"is_Judging\": \"Judging vs Perceiving\",\n",
    "    }\n",
    "\n",
    "    trans_list = [\n",
    "        {0: \"I\", 1: \"E\"},\n",
    "        {0: \"N\", 1: \"S\"},\n",
    "        {0: \"F\", 1: \"T\"},\n",
    "        {0: \"J\", 1: \"P\"},\n",
    "    ]\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=1)\n",
    "\n",
    "    # to time the individual model run time\n",
    "    t = time.time()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for col in target.columns:\n",
    "\n",
    "        print(f\"\\n{mbti_type[col]}\")\n",
    "        y = target[col]\n",
    "        auc_list, acc_list, f1_list = [], [], []\n",
    "\n",
    "        #         X_train, X_test, y_train, y_test = train_test_split(\n",
    "        #             X, target[col], random_state=0, test_size=0.20, stratify=target[col]\n",
    "        #         )\n",
    "\n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "\n",
    "            X_train, X_test, y_train, y_test = (\n",
    "                X.iloc[train_index],\n",
    "                X.iloc[test_index],\n",
    "                y[train_index],\n",
    "                y[test_index],\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            #         predictions.append(y_pred)\n",
    "            #             print(\"RESULT\", y_pred)\n",
    "\n",
    "            preds = model.predict_proba(X_test)[\n",
    "                :, 1\n",
    "            ]  # returns the probablity of class 1\n",
    "            auc = roc_auc_score(y_test, preds)\n",
    "            acc = accuracy_score(y_test, preds.round())\n",
    "            f1 = f1_score(y_test, preds.round())\n",
    "\n",
    "            #         auc = roc_auc_score(y_test, y_pred)\n",
    "            #         acc = accuracy_score(y_test, y_pred)\n",
    "            #         f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            auc_list.append(auc)\n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "\n",
    "        #         print(f\"Avg AUC: {auc:.2f}, Avg Accuracy: {acc:.2f}, Avg F1: {f1:.2f}\")\n",
    "        print(\n",
    "            f\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\"\n",
    "        )\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    #         print(\"Cross val score:\", cross_val_score(model, X, y[col], cv=5, scoring=\"f1\"))\n",
    "\n",
    "    print(f\"\\nTime Taken: {time.time()-t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.63, Avg F1: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      1335\n",
      "           1       0.34      0.61      0.43       400\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.59      0.63      0.58      1735\n",
      "weighted avg       0.73      0.63      0.66      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.67, Avg Accuracy: 0.63, Avg F1: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74      1495\n",
      "           1       0.21      0.64      0.32       240\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.56      0.63      0.53      1735\n",
      "weighted avg       0.82      0.63      0.68      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.84, Avg Accuracy: 0.76, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       938\n",
      "           1       0.72      0.77      0.74       797\n",
      "\n",
      "    accuracy                           0.76      1735\n",
      "   macro avg       0.76      0.76      0.76      1735\n",
      "weighted avg       0.76      0.76      0.76      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.66, Avg Accuracy: 0.61, Avg F1: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66      1049\n",
      "           1       0.51      0.61      0.56       686\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.61      0.62      0.61      1735\n",
      "weighted avg       0.63      0.62      0.62      1735\n",
      "\n",
      "\n",
      "Time Taken: 20.98 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\n# clf_tf = LogisticRegression(class_weight=\\\"balanced\\\")\\n\\nclf_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\\ncreate_model(clf_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\n# clf_tf = LogisticRegression(class_weight=\\\"balanced\\\")\\n\\nclf_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\\ncreate_model(clf_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "# clf_tf = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "clf_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\n",
    "create_model(clf_tf, X_tf, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Saving this model for app testing\\n\\ndump(clf_tf, \\\"clf.joblib\\\")\";\n",
       "                var nbb_formatted_code = \"# Saving this model for app testing\\n\\ndump(clf_tf, \\\"clf.joblib\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving this model for app testing\n",
    "\n",
    "dump(clf_tf, \"clf.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.63, Avg F1: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73      1335\n",
      "           1       0.35      0.65      0.45       400\n",
      "\n",
      "    accuracy                           0.64      1735\n",
      "   macro avg       0.60      0.64      0.59      1735\n",
      "weighted avg       0.74      0.64      0.67      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.62, Avg F1: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.60      0.73      1495\n",
      "           1       0.21      0.68      0.33       240\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.57      0.64      0.53      1735\n",
      "weighted avg       0.82      0.61      0.67      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.84, Avg Accuracy: 0.76, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       938\n",
      "           1       0.71      0.77      0.74       797\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.75      0.75      0.75      1735\n",
      "weighted avg       0.75      0.75      0.75      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.66, Avg Accuracy: 0.61, Avg F1: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67      1049\n",
      "           1       0.52      0.60      0.55       686\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.61      0.62      0.61      1735\n",
      "weighted avg       0.63      0.62      0.62      1735\n",
      "\n",
      "\n",
      "Time Taken: 18.18 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# using Count vectorized data\\n# clf_ct = LogisticRegression()\\n\\nclf_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\\ncreate_model(clf_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using Count vectorized data\\n# clf_ct = LogisticRegression()\\n\\nclf_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\\ncreate_model(clf_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Count vectorized data\n",
    "# clf_ct = LogisticRegression()\n",
    "\n",
    "clf_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression())\n",
    "create_model(clf_ct, X_ct, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.72, Avg Accuracy: 0.65, Avg F1: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      1335\n",
      "           1       0.38      0.67      0.48       400\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.62      0.67      0.62      1735\n",
      "weighted avg       0.76      0.67      0.69      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.72, Avg Accuracy: 0.65, Avg F1: 0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.65      0.76      1495\n",
      "           1       0.24      0.69      0.35       240\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.58      0.67      0.56      1735\n",
      "weighted avg       0.83      0.65      0.71      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.83, Avg Accuracy: 0.76, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       938\n",
      "           1       0.71      0.73      0.72       797\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.74      0.74      0.74      1735\n",
      "weighted avg       0.74      0.74      0.74      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.66, Avg Accuracy: 0.62, Avg F1: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1049\n",
      "           1       0.52      0.58      0.55       686\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.61      0.61      0.61      1735\n",
      "weighted avg       0.63      0.62      0.62      1735\n",
      "\n",
      "\n",
      "Time Taken: 9.69 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\n# nb_tf = MultinomialNB()\\n# create_model(nb_tf, X_tf, y, num_splits=5)\\n\\nnb_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\\ncreate_model(nb_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\n# nb_tf = MultinomialNB()\\n# create_model(nb_tf, X_tf, y, num_splits=5)\\n\\nnb_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\\ncreate_model(nb_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "# nb_tf = MultinomialNB()\n",
    "# create_model(nb_tf, X_tf, y, num_splits=5)\n",
    "\n",
    "nb_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\n",
    "create_model(nb_tf, X_tf, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.71, Avg Accuracy: 0.64, Avg F1: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.65      0.74      1335\n",
      "           1       0.36      0.66      0.47       400\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.61      0.65      0.60      1735\n",
      "weighted avg       0.75      0.65      0.68      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.71, Avg Accuracy: 0.63, Avg F1: 0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.64      0.75      1495\n",
      "           1       0.23      0.68      0.34       240\n",
      "\n",
      "    accuracy                           0.64      1735\n",
      "   macro avg       0.58      0.66      0.55      1735\n",
      "weighted avg       0.83      0.64      0.70      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.83, Avg Accuracy: 0.75, Avg F1: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       938\n",
      "           1       0.72      0.74      0.73       797\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.74      0.75      0.75      1735\n",
      "weighted avg       0.75      0.75      0.75      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.65, Avg Accuracy: 0.61, Avg F1: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68      1049\n",
      "           1       0.52      0.56      0.54       686\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.61      0.61      0.61      1735\n",
      "weighted avg       0.63      0.62      0.62      1735\n",
      "\n",
      "\n",
      "Time Taken: 11.32 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# using Count vectorized data\\n# nb_ct = MultinomialNB()\\n# create_model(nb_ct, X_ct, y, num_splits=5)\\n\\nnb_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\\ncreate_model(nb_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using Count vectorized data\\n# nb_ct = MultinomialNB()\\n# create_model(nb_ct, X_ct, y, num_splits=5)\\n\\nnb_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\\ncreate_model(nb_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Count vectorized data\n",
    "# nb_ct = MultinomialNB()\n",
    "# create_model(nb_ct, X_ct, y, num_splits=5)\n",
    "\n",
    "nb_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\n",
    "create_model(nb_ct, X_ct, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.63, Avg F1: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      1335\n",
      "           1       0.34      0.62      0.44       400\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.59      0.63      0.58      1735\n",
      "weighted avg       0.73      0.63      0.66      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.67, Avg Accuracy: 0.61, Avg F1: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.75      1495\n",
      "           1       0.23      0.67      0.34       240\n",
      "\n",
      "    accuracy                           0.64      1735\n",
      "   macro avg       0.58      0.65      0.55      1735\n",
      "weighted avg       0.83      0.64      0.70      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.80, Avg Accuracy: 0.73, Avg F1: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       938\n",
      "           1       0.67      0.75      0.71       797\n",
      "\n",
      "    accuracy                           0.71      1735\n",
      "   macro avg       0.72      0.72      0.71      1735\n",
      "weighted avg       0.72      0.71      0.72      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.65, Avg Accuracy: 0.60, Avg F1: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65      1049\n",
      "           1       0.50      0.60      0.55       686\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.60      0.60      0.60      1735\n",
      "weighted avg       0.62      0.61      0.61      1735\n",
      "\n",
      "\n",
      "Time Taken: 61.04 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\n# rf_tf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\\\"balanced\\\")\\n# create_model(rf_tf, X_tf, y, num_splits=5)\\n\\nrf_tf = imb_make_pipeline(\\n    MinMaxScaler(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=8),\\n)\\ncreate_model(rf_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\n# rf_tf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\\\"balanced\\\")\\n# create_model(rf_tf, X_tf, y, num_splits=5)\\n\\nrf_tf = imb_make_pipeline(\\n    MinMaxScaler(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=8),\\n)\\ncreate_model(rf_tf, X_tf, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "# rf_tf = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\"balanced\")\n",
    "# create_model(rf_tf, X_tf, y, num_splits=5)\n",
    "\n",
    "rf_tf = imb_make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RandomUnderSampler(),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=8),\n",
    ")\n",
    "create_model(rf_tf, X_tf, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.69, Avg Accuracy: 0.64, Avg F1: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75      1335\n",
      "           1       0.37      0.64      0.47       400\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.61      0.65      0.61      1735\n",
      "weighted avg       0.75      0.66      0.69      1735\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.67, Avg Accuracy: 0.62, Avg F1: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73      1495\n",
      "           1       0.20      0.61      0.30       240\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.55      0.61      0.52      1735\n",
      "weighted avg       0.81      0.61      0.67      1735\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.80, Avg Accuracy: 0.72, Avg F1: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       938\n",
      "           1       0.67      0.73      0.70       797\n",
      "\n",
      "    accuracy                           0.71      1735\n",
      "   macro avg       0.71      0.71      0.71      1735\n",
      "weighted avg       0.72      0.71      0.71      1735\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.64, Avg Accuracy: 0.61, Avg F1: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.67      0.67      1049\n",
      "           1       0.51      0.53      0.52       686\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.59      0.60      0.60      1735\n",
      "weighted avg       0.61      0.61      0.61      1735\n",
      "\n",
      "\n",
      "Time Taken: 38.81 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\n# rf_ct = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\\\"balanced\\\")\\n# create_model(rf_ct, X_ct, y, num_splits=5)\\n\\n\\nrf_ct = imb_make_pipeline(\\n    MinMaxScaler(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=8),\\n)\\ncreate_model(rf_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\n# rf_ct = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\\\"balanced\\\")\\n# create_model(rf_ct, X_ct, y, num_splits=5)\\n\\n\\nrf_ct = imb_make_pipeline(\\n    MinMaxScaler(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=8),\\n)\\ncreate_model(rf_ct, X_ct, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "# rf_ct = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight=\"balanced\")\n",
    "# create_model(rf_ct, X_ct, y, num_splits=5)\n",
    "\n",
    "\n",
    "rf_ct = imb_make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RandomUnderSampler(),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=8),\n",
    ")\n",
    "create_model(rf_ct, X_ct, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC AUC Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# from sklearn.metrics import roc_curve, auc\\n\\n# fpr = dict()\\n# tpr = dict()\\n# roc_auc = dict()\\n# for i in range(2):\\n#     fpr[i], tpr[i], _ = roc_curve(y_test, pred)\\n#     roc_auc[i] = auc(fpr[i], tpr[i])\\n\\n# print roc_auc_score(test, pred)\\n# plt.figure()\\n# plt.plot(fpr[1], tpr[1])\\n# plt.xlim([0.0, 1.0])\\n# plt.ylim([0.0, 1.05])\\n# plt.xlabel(\\\"False Positive Rate\\\")\\n# plt.ylabel(\\\"True Positive Rate\\\")\\n# plt.title(\\\"Receiver operating characteristic\\\")\\n# plt.show()\";\n",
       "                var nbb_formatted_code = \"# from sklearn.metrics import roc_curve, auc\\n\\n# fpr = dict()\\n# tpr = dict()\\n# roc_auc = dict()\\n# for i in range(2):\\n#     fpr[i], tpr[i], _ = roc_curve(y_test, pred)\\n#     roc_auc[i] = auc(fpr[i], tpr[i])\\n\\n# print roc_auc_score(test, pred)\\n# plt.figure()\\n# plt.plot(fpr[1], tpr[1])\\n# plt.xlim([0.0, 1.0])\\n# plt.ylim([0.0, 1.05])\\n# plt.xlabel(\\\"False Positive Rate\\\")\\n# plt.ylabel(\\\"True Positive Rate\\\")\\n# plt.title(\\\"Receiver operating characteristic\\\")\\n# plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# for i in range(2):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test, pred)\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# print roc_auc_score(test, pred)\n",
    "# plt.figure()\n",
    "# plt.plot(fpr[1], tpr[1])\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"Receiver operating characteristic\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# model_list = [lr_tf_model, lr_ct_model, mnb_tf_model, mnb_ct_model]\\n# model_names = ['LR TFIDF', 'LR Word ct','MNB TFIDF', 'MNB Word ct']\\n# plot_\";\n",
       "                var nbb_formatted_code = \"# model_list = [lr_tf_model, lr_ct_model, mnb_tf_model, mnb_ct_model]\\n# model_names = ['LR TFIDF', 'LR Word ct','MNB TFIDF', 'MNB Word ct']\\n# plot_\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_list = [lr_tf_model, lr_ct_model, mnb_tf_model, mnb_ct_model]\n",
    "# model_names = ['LR TFIDF', 'LR Word ct','MNB TFIDF', 'MNB Word ct']\n",
    "# plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FInal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
