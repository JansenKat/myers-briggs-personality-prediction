{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (MBTI) Myers-Briggs Personality Type Prediction\n",
    "\n",
    "* Extroversion vs. Introversion\n",
    "    * I - 0\n",
    "    * E - 1 \n",
    "    \n",
    "* Sensing vs. Intuition \n",
    "    * N - 0 \n",
    "    * S - 1\n",
    "    \n",
    "* Thinking vs. Feeling\n",
    "    * F - 0\n",
    "    * T - 1\n",
    "    \n",
    "* Judging vs. Perceiving\n",
    "    * P - 0\n",
    "    * J - 1 \n",
    "    \n",
    "## IMPLEMENTING DIFFERENT MODELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data stratifying and splitting\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# class imbalance\n",
    "from imblearn.pipeline import make_pipeline as imb_make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# algorithms/models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.feature_selection import f_classif\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# model performance evaluation and selection\n",
    "\n",
    "\n",
    "# performance check\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# sparse to dense\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "\n",
    "# saving the model\n",
    "from joblib import dump\n",
    "\n",
    "# code formatter\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# reading the final datasets\\npersonality_data = pd.read_csv(\\\"data_ekta/clean_data_3.csv\\\")\\n# tfidf_vectorized_data = pd.read_csv(\\\"data_ekta/tfidf_vectorized_data.csv\\\")\\n# count_vectorized_data = pd.read_csv(\\\"data_ekta/count_vectorized_data.csv\\\")\";\n",
       "                var nbb_formatted_code = \"# reading the final datasets\\npersonality_data = pd.read_csv(\\\"data_ekta/clean_data_3.csv\\\")\\n# tfidf_vectorized_data = pd.read_csv(\\\"data_ekta/tfidf_vectorized_data.csv\\\")\\n# count_vectorized_data = pd.read_csv(\\\"data_ekta/count_vectorized_data.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading the final datasets\n",
    "personality_data = pd.read_csv(\"data_ekta/clean_data_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_Extrovert</th>\n",
       "      <th>is_Sensing</th>\n",
       "      <th>is_Thinking</th>\n",
       "      <th>is_Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>colons</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>avg_word_ct</th>\n",
       "      <th>post_length_var</th>\n",
       "      <th>upper</th>\n",
       "      <th>link_count</th>\n",
       "      <th>ellipses</th>\n",
       "      <th>img_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'When asked of the things you wish you did ear...</td>\n",
       "      <td>asked thing wish earlier       find answering...</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>0.404284</td>\n",
       "      <td>0.133020</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1549</td>\n",
       "      <td>746</td>\n",
       "      <td>30.98</td>\n",
       "      <td>78.414931</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'I love both and they are equally important to...</td>\n",
       "      <td>love equally important  music window soul  in...</td>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.601071</td>\n",
       "      <td>0.131455</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1429</td>\n",
       "      <td>636</td>\n",
       "      <td>28.58</td>\n",
       "      <td>160.744400</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_Extrovert  is_Sensing  is_Thinking  is_Judging  \\\n",
       "0  INFJ             0           0            0           1   \n",
       "1  INFJ             0           0            0           1   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'When asked of the things you wish you did ear...   \n",
       "1  'I love both and they are equally important to...   \n",
       "\n",
       "                                         clean_posts  compound_sentiment  \\\n",
       "0   asked thing wish earlier       find answering...             0.99980   \n",
       "1   love equally important  music window soul  in...             0.99995   \n",
       "\n",
       "   pos_sentiment  neg_sentiment  ...  colons emojis word_count  unique_words  \\\n",
       "0       0.404284       0.133020  ...      16      4       1549           746   \n",
       "1       0.601071       0.131455  ...       7      0       1429           636   \n",
       "\n",
       "   avg_word_ct  post_length_var  upper  link_count  ellipses  img_count  \n",
       "0        30.98        78.414931     73           2        31          0  \n",
       "1        28.58       160.744400     81           1         2          0  \n",
       "\n",
       "[2 rows x 139 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# checking counts dataset\\npersonality_data.head(2)\";\n",
       "                var nbb_formatted_code = \"# checking counts dataset\\npersonality_data.head(2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking counts dataset\n",
    "personality_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting predictors and target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8588, 32)\n",
      "(8588, 4)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X = personality_data[\\n    [\\n        \\\"clean_posts\\\",\\n        \\\"compound_sentiment\\\",\\n        \\\"S_ADJ_med\\\",\\n        \\\"S_ADJ_std\\\",\\n        \\\"S_ADP_med\\\",\\n        \\\"S_ADP_std\\\",\\n        \\\"S_ADV_med\\\",\\n        \\\"S_ADV_std\\\",\\n        \\\"S_CONJ_med\\\",\\n        \\\"S_CONJ_std\\\",\\n        \\\"S_DET_med\\\",\\n        \\\"S_DET_std\\\",\\n        \\\"S_NOUN_med\\\",\\n        \\\"S_NOUN_std\\\",\\n        \\\"S_NUM_med\\\",\\n        \\\"S_NUM_std\\\",\\n        \\\"S_PRT_med\\\",\\n        \\\"S_PRT_std\\\",\\n        \\\"S_PRON_med\\\",\\n        \\\"S_PRON_std\\\",\\n        \\\"S_VERB_med\\\",\\n        \\\"S_VERB_std\\\",\\n        \\\"qm\\\",\\n        \\\"em\\\",\\n        \\\"colons\\\",\\n        \\\"emojis\\\",\\n        \\\"word_count\\\",\\n        \\\"unique_words\\\",\\n          \\\"upper\\\",\\n        \\\"link_count\\\",\\n        \\\"ellipses\\\",\\n        \\\"img_count\\\",\\n    ]\\n]\\n\\ny = personality_data.iloc[:, 1:5]\\n\\n\\nprint(X.shape)\\nprint(y.shape)\";\n",
       "                var nbb_formatted_code = \"X = personality_data[\\n    [\\n        \\\"clean_posts\\\",\\n        \\\"compound_sentiment\\\",\\n        \\\"S_ADJ_med\\\",\\n        \\\"S_ADJ_std\\\",\\n        \\\"S_ADP_med\\\",\\n        \\\"S_ADP_std\\\",\\n        \\\"S_ADV_med\\\",\\n        \\\"S_ADV_std\\\",\\n        \\\"S_CONJ_med\\\",\\n        \\\"S_CONJ_std\\\",\\n        \\\"S_DET_med\\\",\\n        \\\"S_DET_std\\\",\\n        \\\"S_NOUN_med\\\",\\n        \\\"S_NOUN_std\\\",\\n        \\\"S_NUM_med\\\",\\n        \\\"S_NUM_std\\\",\\n        \\\"S_PRT_med\\\",\\n        \\\"S_PRT_std\\\",\\n        \\\"S_PRON_med\\\",\\n        \\\"S_PRON_std\\\",\\n        \\\"S_VERB_med\\\",\\n        \\\"S_VERB_std\\\",\\n        \\\"qm\\\",\\n        \\\"em\\\",\\n        \\\"colons\\\",\\n        \\\"emojis\\\",\\n        \\\"word_count\\\",\\n        \\\"unique_words\\\",\\n        \\\"upper\\\",\\n        \\\"link_count\\\",\\n        \\\"ellipses\\\",\\n        \\\"img_count\\\",\\n    ]\\n]\\n\\ny = personality_data.iloc[:, 1:5]\\n\\n\\nprint(X.shape)\\nprint(y.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = personality_data[\n",
    "    [\n",
    "        \"clean_posts\",\n",
    "        \"compound_sentiment\",\n",
    "        \"S_ADJ_med\",\n",
    "        \"S_ADJ_std\",\n",
    "        \"S_ADP_med\",\n",
    "        \"S_ADP_std\",\n",
    "        \"S_ADV_med\",\n",
    "        \"S_ADV_std\",\n",
    "        \"S_CONJ_med\",\n",
    "        \"S_CONJ_std\",\n",
    "        \"S_DET_med\",\n",
    "        \"S_DET_std\",\n",
    "        \"S_NOUN_med\",\n",
    "        \"S_NOUN_std\",\n",
    "        \"S_NUM_med\",\n",
    "        \"S_NUM_std\",\n",
    "        \"S_PRT_med\",\n",
    "        \"S_PRT_std\",\n",
    "        \"S_PRON_med\",\n",
    "        \"S_PRON_std\",\n",
    "        \"S_VERB_med\",\n",
    "        \"S_VERB_std\",\n",
    "        \"qm\",\n",
    "        \"em\",\n",
    "        \"colons\",\n",
    "        \"emojis\",\n",
    "        \"word_count\",\n",
    "        \"unique_words\",\n",
    "        \"upper\",\n",
    "        \"link_count\",\n",
    "        \"ellipses\",\n",
    "        \"img_count\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "y = personality_data.iloc[:, 1:5]\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up preprocessor for vectorization and selecting best counts and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# preprocessing steps for selecting best k columns/features from counts & scores and for vectorizing words\\n# words = [\\\"clean_posts\\\"]\\n\\ncounts_n_scores = [\\n    \\\"compound_sentiment\\\",\\n    \\\"S_ADJ_med\\\",\\n    \\\"S_ADJ_std\\\",\\n    \\\"S_ADP_med\\\",\\n    \\\"S_ADP_std\\\",\\n    \\\"S_ADV_med\\\",\\n    \\\"S_ADV_std\\\",\\n    \\\"S_CONJ_med\\\",\\n    \\\"S_CONJ_std\\\",\\n    \\\"S_DET_med\\\",\\n    \\\"S_DET_std\\\",\\n    \\\"S_NOUN_med\\\",\\n    \\\"S_NOUN_std\\\",\\n    \\\"S_NUM_med\\\",\\n    \\\"S_NUM_std\\\",\\n    \\\"S_PRT_med\\\",\\n    \\\"S_PRT_std\\\",\\n    \\\"S_PRON_med\\\",\\n    \\\"S_PRON_std\\\",\\n    \\\"S_VERB_med\\\",\\n    \\\"S_VERB_std\\\",\\n    \\\"qm\\\",\\n    \\\"em\\\",\\n    \\\"colons\\\",\\n    \\\"emojis\\\",\\n    \\\"word_count\\\",\\n    \\\"unique_words\\\",\\n    #     \\\"avg_word_ct\\\",\\n    #     \\\"post_length_var\\\",\\n    \\\"upper\\\",\\n    \\\"link_count\\\",\\n    \\\"ellipses\\\",\\n    \\\"img_count\\\",\\n]\\n\\nbest_k_features = make_pipeline(MinMaxScaler(), SelectKBest(f_classif, k=5))\\n\\n# best_k_words = make_pipeline(\\n#     TfidfVectorizer(min_df=25, max_df=0.8,), SelectKBest(f_classif, k=1000)\\n# )\\n\\n\\n# setting up preprocessing for tf-idf vectorizer\\npreprocesser_tf = ColumnTransformer(\\n    transformers=[\\n        (\\\"tfidf\\\", TfidfVectorizer(min_df=25, max_df=0.8,), \\\"clean_posts\\\",),\\n        #         (\\\"bestwords\\\", best_k_words, \\\"clean_posts\\\"),\\n        (\\\"selectbest\\\", best_k_features, counts_n_scores),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n# setting up preprocessing for count vectorizer\\npreprocesser_ct = ColumnTransformer(\\n    transformers=[\\n    (\\\"ct_vect\\\", CountVectorizer(min_df=25, max_df=0.8,), \\\"clean_posts\\\",),\\n    (\\\"selectbest\\\", best_k_features, counts_n_scores),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"# preprocessing steps for selecting best k columns/features from counts & scores and for vectorizing words\\n# words = [\\\"clean_posts\\\"]\\n\\ncounts_n_scores = [\\n    \\\"compound_sentiment\\\",\\n    \\\"S_ADJ_med\\\",\\n    \\\"S_ADJ_std\\\",\\n    \\\"S_ADP_med\\\",\\n    \\\"S_ADP_std\\\",\\n    \\\"S_ADV_med\\\",\\n    \\\"S_ADV_std\\\",\\n    \\\"S_CONJ_med\\\",\\n    \\\"S_CONJ_std\\\",\\n    \\\"S_DET_med\\\",\\n    \\\"S_DET_std\\\",\\n    \\\"S_NOUN_med\\\",\\n    \\\"S_NOUN_std\\\",\\n    \\\"S_NUM_med\\\",\\n    \\\"S_NUM_std\\\",\\n    \\\"S_PRT_med\\\",\\n    \\\"S_PRT_std\\\",\\n    \\\"S_PRON_med\\\",\\n    \\\"S_PRON_std\\\",\\n    \\\"S_VERB_med\\\",\\n    \\\"S_VERB_std\\\",\\n    \\\"qm\\\",\\n    \\\"em\\\",\\n    \\\"colons\\\",\\n    \\\"emojis\\\",\\n    \\\"word_count\\\",\\n    \\\"unique_words\\\",\\n    #     \\\"avg_word_ct\\\",\\n    #     \\\"post_length_var\\\",\\n    \\\"upper\\\",\\n    \\\"link_count\\\",\\n    \\\"ellipses\\\",\\n    \\\"img_count\\\",\\n]\\n\\nbest_k_features = make_pipeline(MinMaxScaler(), SelectKBest(f_classif, k=5))\\n\\n# best_k_words = make_pipeline(\\n#     TfidfVectorizer(min_df=25, max_df=0.8,), SelectKBest(f_classif, k=1000)\\n# )\\n\\n\\n# setting up preprocessing for tf-idf vectorizer\\npreprocesser_tf = ColumnTransformer(\\n    transformers=[\\n        (\\\"tfidf\\\", TfidfVectorizer(min_df=25, max_df=0.8,), \\\"clean_posts\\\",),\\n        #         (\\\"bestwords\\\", best_k_words, \\\"clean_posts\\\"),\\n        (\\\"selectbest\\\", best_k_features, counts_n_scores),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\\n\\n# setting up preprocessing for count vectorizer\\npreprocesser_ct = ColumnTransformer(\\n    transformers=[\\n        (\\\"ct_vect\\\", CountVectorizer(min_df=25, max_df=0.8,), \\\"clean_posts\\\",),\\n        (\\\"selectbest\\\", best_k_features, counts_n_scores),\\n    ],\\n    remainder=\\\"passthrough\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocessing steps for selecting best k columns/features from counts & scores and for vectorizing words\n",
    "\n",
    "counts_n_scores = [\n",
    "    \"compound_sentiment\",\n",
    "    \"S_ADJ_med\",\n",
    "    \"S_ADJ_std\",\n",
    "    \"S_ADP_med\",\n",
    "    \"S_ADP_std\",\n",
    "    \"S_ADV_med\",\n",
    "    \"S_ADV_std\",\n",
    "    \"S_CONJ_med\",\n",
    "    \"S_CONJ_std\",\n",
    "    \"S_DET_med\",\n",
    "    \"S_DET_std\",\n",
    "    \"S_NOUN_med\",\n",
    "    \"S_NOUN_std\",\n",
    "    \"S_NUM_med\",\n",
    "    \"S_NUM_std\",\n",
    "    \"S_PRT_med\",\n",
    "    \"S_PRT_std\",\n",
    "    \"S_PRON_med\",\n",
    "    \"S_PRON_std\",\n",
    "    \"S_VERB_med\",\n",
    "    \"S_VERB_std\",\n",
    "    \"qm\",\n",
    "    \"em\",\n",
    "    \"colons\",\n",
    "    \"emojis\",\n",
    "    \"word_count\",\n",
    "    \"unique_words\",\n",
    "    \"upper\",\n",
    "    \"link_count\",\n",
    "    \"ellipses\",\n",
    "    \"img_count\",\n",
    "]\n",
    "\n",
    "best_k_features = make_pipeline(MinMaxScaler(), SelectKBest(f_classif, k=5))\n",
    "\n",
    "# best_k_words = make_pipeline(\n",
    "#     TfidfVectorizer(min_df=25, max_df=0.8,), SelectKBest(f_classif, k=1000)\n",
    "# )\n",
    "\n",
    "\n",
    "# setting up preprocessing for tf-idf vectorizer\n",
    "preprocesser_tf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", TfidfVectorizer(min_df=25, max_df=0.8,), \"clean_posts\",),\n",
    "        #         (\"bestwords\", best_k_words, \"clean_posts\"),\n",
    "        (\"selectbest\", best_k_features, counts_n_scores),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# setting up preprocessing for count vectorizer\n",
    "preprocesser_ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ct_vect\", CountVectorizer(min_df=25, max_df=0.8,), \"clean_posts\",),\n",
    "        (\"selectbest\", best_k_features, counts_n_scores),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def create_model(model, X, target, nsplits):\\n\\n    mbti_type = {\\n        \\\"is_Extrovert\\\": \\\"Extrovert vs Introvert\\\",\\n        \\\"is_Sensing\\\": \\\"Sensing vs Intuition\\\",\\n        \\\"is_Thinking\\\": \\\"Thinking vs Feeling\\\",\\n        \\\"is_Judging\\\": \\\"Judging vs Perceiving\\\",\\n    }\\n\\n    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=100)\\n\\n    # to time the individual model run time\\n    t = time.time()\\n\\n    predictions = []\\n\\n    for col in target.columns:\\n\\n        print(f\\\"\\\\n{mbti_type[col]}\\\")\\n        y = target[col]\\n        auc_list, acc_list, f1_list = [], [], []\\n\\n        for train_index, test_index in kfold.split(X, y):\\n\\n            X_train, X_test, y_train, y_test = (\\n                X.iloc[train_index],\\n                X.iloc[test_index],\\n                y[train_index],\\n                y[test_index],\\n            )\\n\\n            model.fit(X_train, y_train)\\n            \\n#             importance = f_classif(X_train, y_train)\\n#             print(importance)\\n            \\n            y_pred = model.predict(X_test)\\n\\n            preds = model.predict_proba(X_test)[\\n                :, 1\\n            ]  # returns the probablity of class 1\\n            auc = roc_auc_score(y_test, preds)\\n            acc = accuracy_score(y_test, y_pred)\\n            f1 = f1_score(y_test, y_pred, average=\\\"weighted\\\")\\n\\n            auc_list.append(auc)\\n            acc_list.append(acc)\\n            f1_list.append(f1)\\n            \\n            dump(model, f\\\"clf_{col}.joblib\\\")\\n\\n        print(\\n            f\\\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\\\"\\n        )\\n        print(classification_report(y_test, y_pred))\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")   \\n \";\n",
       "                var nbb_formatted_code = \"def create_model(model, X, target, nsplits):\\n\\n    mbti_type = {\\n        \\\"is_Extrovert\\\": \\\"Extrovert vs Introvert\\\",\\n        \\\"is_Sensing\\\": \\\"Sensing vs Intuition\\\",\\n        \\\"is_Thinking\\\": \\\"Thinking vs Feeling\\\",\\n        \\\"is_Judging\\\": \\\"Judging vs Perceiving\\\",\\n    }\\n\\n    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=100)\\n\\n    # to time the individual model run time\\n    t = time.time()\\n\\n    predictions = []\\n\\n    for col in target.columns:\\n\\n        print(f\\\"\\\\n{mbti_type[col]}\\\")\\n        y = target[col]\\n        auc_list, acc_list, f1_list = [], [], []\\n\\n        for train_index, test_index in kfold.split(X, y):\\n\\n            X_train, X_test, y_train, y_test = (\\n                X.iloc[train_index],\\n                X.iloc[test_index],\\n                y[train_index],\\n                y[test_index],\\n            )\\n\\n            model.fit(X_train, y_train)\\n\\n            #             importance = f_classif(X_train, y_train)\\n            #             print(importance)\\n\\n            y_pred = model.predict(X_test)\\n\\n            preds = model.predict_proba(X_test)[\\n                :, 1\\n            ]  # returns the probablity of class 1\\n            auc = roc_auc_score(y_test, preds)\\n            acc = accuracy_score(y_test, y_pred)\\n            f1 = f1_score(y_test, y_pred, average=\\\"weighted\\\")\\n\\n            auc_list.append(auc)\\n            acc_list.append(acc)\\n            f1_list.append(f1)\\n\\n            dump(model, f\\\"clf_{col}.joblib\\\")\\n\\n        print(\\n            f\\\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\\\"\\n        )\\n        print(classification_report(y_test, y_pred))\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(model, X, target, nsplits):\n",
    "\n",
    "    mbti_type = {\n",
    "        \"is_Extrovert\": \"Extrovert vs Introvert\",\n",
    "        \"is_Sensing\": \"Sensing vs Intuition\",\n",
    "        \"is_Thinking\": \"Thinking vs Feeling\",\n",
    "        \"is_Judging\": \"Judging vs Perceiving\",\n",
    "    }\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=nsplits, shuffle=True, random_state=100)\n",
    "\n",
    "    # to time the individual model run time\n",
    "    t = time.time()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for col in target.columns:\n",
    "\n",
    "        print(f\"\\n{mbti_type[col]}\")\n",
    "        y = target[col]\n",
    "        auc_list, acc_list, f1_list = [], [], []\n",
    "\n",
    "        for train_index, test_index in kfold.split(X, y):\n",
    "\n",
    "            X_train, X_test, y_train, y_test = (\n",
    "                X.iloc[train_index],\n",
    "                X.iloc[test_index],\n",
    "                y[train_index],\n",
    "                y[test_index],\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "      \n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            preds = model.predict_proba(X_test)[\n",
    "                :, 1\n",
    "            ]  # returns the probablity of class 1\n",
    "            auc = roc_auc_score(y_test, preds)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "            auc_list.append(auc)\n",
    "            acc_list.append(acc)\n",
    "            f1_list.append(f1)\n",
    "            \n",
    "            dump(model, f\"clf_{col}.joblib\")\n",
    "\n",
    "        print(\n",
    "            f\"Avg AUC: {np.mean(auc_list):.2f}, Avg Accuracy: {np.mean(acc_list):.2f}, Avg F1: {np.mean(f1_list):.2f}\"\n",
    "        )\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(f\"\\nTime Taken: {time.time()-t:.2f} seconds\")   \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.76, Avg Accuracy: 0.70, Avg F1: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79      1321\n",
      "           1       0.41      0.66      0.51       396\n",
      "\n",
      "    accuracy                           0.70      1717\n",
      "   macro avg       0.64      0.69      0.65      1717\n",
      "weighted avg       0.77      0.70      0.72      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.76, Avg Accuracy: 0.69, Avg F1: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.68      0.79      1480\n",
      "           1       0.25      0.68      0.37       237\n",
      "\n",
      "    accuracy                           0.68      1717\n",
      "   macro avg       0.59      0.68      0.58      1717\n",
      "weighted avg       0.84      0.68      0.73      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.88, Avg Accuracy: 0.79, Avg F1: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       929\n",
      "           1       0.74      0.82      0.78       788\n",
      "\n",
      "    accuracy                           0.79      1717\n",
      "   macro avg       0.79      0.79      0.79      1717\n",
      "weighted avg       0.79      0.79      0.79      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.73, Avg Accuracy: 0.67, Avg F1: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      1037\n",
      "           1       0.57      0.67      0.62       680\n",
      "\n",
      "    accuracy                           0.67      1717\n",
      "   macro avg       0.66      0.67      0.66      1717\n",
      "weighted avg       0.68      0.67      0.67      1717\n",
      "\n",
      "\n",
      "Time Taken: 122.06 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\nclf_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    #     DenseTransformer(),\\n    RandomUnderSampler(),\\n    LogisticRegression(),\\n)\\ncreate_model(clf_tf, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\nclf_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    #     DenseTransformer(),\\n    RandomUnderSampler(),\\n    LogisticRegression(),\\n)\\ncreate_model(clf_tf, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "clf_tf = imb_make_pipeline(\n",
    "    preprocesser_tf,\n",
    "    #     DenseTransformer(),\n",
    "    RandomUnderSampler(),\n",
    "    LogisticRegression(),\n",
    ")\n",
    "create_model(clf_tf, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# lr = clf_tf[-1]\\n# importance = lr.coef_[0]\\n# importance = f_classif(X_train, y_train)\\n# summarize feature importance\\n# for i, v in enumerate(importance):\\n#     print(\\\"Feature: %0d, Score: %.5f\\\" % (i, v))\\n# # plot feature importance\\n# plt.bar([x for x in range(len(importance))], importance)\\n# plt.show()\";\n",
       "                var nbb_formatted_code = \"# lr = clf_tf[-1]\\n# importance = lr.coef_[0]\\n# importance = f_classif(X_train, y_train)\\n# summarize feature importance\\n# for i, v in enumerate(importance):\\n#     print(\\\"Feature: %0d, Score: %.5f\\\" % (i, v))\\n# # plot feature importance\\n# plt.bar([x for x in range(len(importance))], importance)\\n# plt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr = clf_tf[-1]\n",
    "# importance = lr.coef_[0]\n",
    "# importance = f_classif(X_train, y_train)\n",
    "# summarize feature importance\n",
    "# for i, v in enumerate(importance):\n",
    "#     print(\"Feature: %0d, Score: %.5f\" % (i, v))\n",
    "# # plot feature importance\n",
    "# plt.bar([x for x in range(len(importance))], importance)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.70, Avg Accuracy: 0.65, Avg F1: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      1321\n",
      "           1       0.34      0.61      0.44       396\n",
      "\n",
      "    accuracy                           0.63      1717\n",
      "   macro avg       0.59      0.63      0.58      1717\n",
      "weighted avg       0.73      0.63      0.66      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.71, Avg Accuracy: 0.65, Avg F1: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.64      0.75      1480\n",
      "           1       0.22      0.64      0.33       237\n",
      "\n",
      "    accuracy                           0.64      1717\n",
      "   macro avg       0.57      0.64      0.54      1717\n",
      "weighted avg       0.82      0.64      0.69      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.83, Avg Accuracy: 0.75, Avg F1: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       929\n",
      "           1       0.71      0.78      0.74       788\n",
      "\n",
      "    accuracy                           0.75      1717\n",
      "   macro avg       0.75      0.75      0.75      1717\n",
      "weighted avg       0.76      0.75      0.75      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.67, Avg Accuracy: 0.62, Avg F1: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      1037\n",
      "           1       0.50      0.58      0.54       680\n",
      "\n",
      "    accuracy                           0.61      1717\n",
      "   macro avg       0.60      0.60      0.60      1717\n",
      "weighted avg       0.62      0.61      0.61      1717\n",
      "\n",
      "\n",
      "Time Taken: 221.41 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# using Count vectorized data\\nclf_ct = imb_make_pipeline(\\n    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\\n)\\ncreate_model(clf_ct, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using Count vectorized data\\nclf_ct = imb_make_pipeline(\\n    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\\n)\\ncreate_model(clf_ct, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Count vectorized data\n",
    "clf_ct = imb_make_pipeline(\n",
    "    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\n",
    ")\n",
    "create_model(clf_ct, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.74, Avg Accuracy: 0.64, Avg F1: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.75      1321\n",
      "           1       0.38      0.71      0.50       396\n",
      "\n",
      "    accuracy                           0.66      1717\n",
      "   macro avg       0.63      0.68      0.62      1717\n",
      "weighted avg       0.77      0.66      0.69      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.77, Avg Accuracy: 0.68, Avg F1: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.80      1480\n",
      "           1       0.27      0.69      0.38       237\n",
      "\n",
      "    accuracy                           0.69      1717\n",
      "   macro avg       0.60      0.69      0.59      1717\n",
      "weighted avg       0.84      0.69      0.74      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.85, Avg Accuracy: 0.77, Avg F1: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       929\n",
      "           1       0.77      0.71      0.74       788\n",
      "\n",
      "    accuracy                           0.77      1717\n",
      "   macro avg       0.77      0.76      0.77      1717\n",
      "weighted avg       0.77      0.77      0.77      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.62, Avg F1: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      1037\n",
      "           1       0.52      0.64      0.57       680\n",
      "\n",
      "    accuracy                           0.63      1717\n",
      "   macro avg       0.62      0.63      0.62      1717\n",
      "weighted avg       0.64      0.63      0.63      1717\n",
      "\n",
      "\n",
      "Time Taken: 145.54 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\nnb_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    DenseTransformer(),\\n    #     MinMaxScaler(),\\n    RandomUnderSampler(),\\n    MultinomialNB(),\\n)\\ncreate_model(nb_tf, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\nnb_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    DenseTransformer(),\\n    #     MinMaxScaler(),\\n    RandomUnderSampler(),\\n    MultinomialNB(),\\n)\\ncreate_model(nb_tf, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "nb_tf = imb_make_pipeline(\n",
    "    preprocesser_tf,\n",
    "    DenseTransformer(),\n",
    "    #     MinMaxScaler(),\n",
    "    RandomUnderSampler(),\n",
    "    MultinomialNB(),\n",
    ")\n",
    "create_model(nb_tf, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.74, Avg Accuracy: 0.68, Avg F1: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77      1321\n",
      "           1       0.40      0.69      0.50       396\n",
      "\n",
      "    accuracy                           0.69      1717\n",
      "   macro avg       0.64      0.69      0.64      1717\n",
      "weighted avg       0.77      0.69      0.71      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.76, Avg Accuracy: 0.69, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79      1480\n",
      "           1       0.25      0.66      0.37       237\n",
      "\n",
      "    accuracy                           0.69      1717\n",
      "   macro avg       0.59      0.67      0.58      1717\n",
      "weighted avg       0.83      0.69      0.73      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.85, Avg Accuracy: 0.77, Avg F1: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79       929\n",
      "           1       0.75      0.76      0.75       788\n",
      "\n",
      "    accuracy                           0.77      1717\n",
      "   macro avg       0.77      0.77      0.77      1717\n",
      "weighted avg       0.77      0.77      0.77      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.64, Avg F1: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70      1037\n",
      "           1       0.56      0.62      0.59       680\n",
      "\n",
      "    accuracy                           0.65      1717\n",
      "   macro avg       0.64      0.65      0.64      1717\n",
      "weighted avg       0.66      0.65      0.66      1717\n",
      "\n",
      "\n",
      "Time Taken: 142.99 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# using Count vectorized data\\nnb_ct = imb_make_pipeline(\\n        preprocesser_ct,\\n        DenseTransformer(),\\n        RandomUnderSampler(),\\n        MultinomialNB(),\\n)\\ncreate_model(nb_ct, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using Count vectorized data\\nnb_ct = imb_make_pipeline(\\n    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), MultinomialNB(),\\n)\\ncreate_model(nb_ct, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Count vectorized data\n",
    "nb_ct = imb_make_pipeline(\n",
    "    preprocesser_ct, DenseTransformer(), RandomUnderSampler(), MultinomialNB(),\n",
    ")\n",
    "create_model(nb_ct, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.69, Avg Accuracy: 0.64, Avg F1: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.73      1321\n",
      "           1       0.34      0.61      0.44       396\n",
      "\n",
      "    accuracy                           0.64      1717\n",
      "   macro avg       0.59      0.63      0.59      1717\n",
      "weighted avg       0.73      0.64      0.67      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.67, Avg Accuracy: 0.63, Avg F1: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74      1480\n",
      "           1       0.20      0.59      0.30       237\n",
      "\n",
      "    accuracy                           0.62      1717\n",
      "   macro avg       0.55      0.61      0.52      1717\n",
      "weighted avg       0.81      0.62      0.68      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.81, Avg Accuracy: 0.74, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       929\n",
      "           1       0.69      0.75      0.72       788\n",
      "\n",
      "    accuracy                           0.73      1717\n",
      "   macro avg       0.73      0.73      0.73      1717\n",
      "weighted avg       0.73      0.73      0.73      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.64, Avg Accuracy: 0.60, Avg F1: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66      1037\n",
      "           1       0.51      0.60      0.55       680\n",
      "\n",
      "    accuracy                           0.61      1717\n",
      "   macro avg       0.61      0.61      0.60      1717\n",
      "weighted avg       0.63      0.61      0.62      1717\n",
      "\n",
      "\n",
      "Time Taken: 277.04 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\nrf_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    DenseTransformer(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=10),\\n)\\ncreate_model(rf_tf, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\nrf_tf = imb_make_pipeline(\\n    preprocesser_tf,\\n    DenseTransformer(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=10),\\n)\\ncreate_model(rf_tf, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "rf_tf = imb_make_pipeline(\n",
    "    preprocesser_tf,\n",
    "    DenseTransformer(),\n",
    "    RandomUnderSampler(),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=10),\n",
    ")\n",
    "create_model(rf_tf, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extrovert vs Introvert\n",
      "Avg AUC: 0.70, Avg Accuracy: 0.65, Avg F1: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.64      0.73      1321\n",
      "           1       0.35      0.64      0.45       396\n",
      "\n",
      "    accuracy                           0.64      1717\n",
      "   macro avg       0.60      0.64      0.59      1717\n",
      "weighted avg       0.74      0.64      0.67      1717\n",
      "\n",
      "\n",
      "Sensing vs Intuition\n",
      "Avg AUC: 0.68, Avg Accuracy: 0.64, Avg F1: 0.70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      1480\n",
      "           1       0.22      0.62      0.32       237\n",
      "\n",
      "    accuracy                           0.64      1717\n",
      "   macro avg       0.56      0.63      0.54      1717\n",
      "weighted avg       0.82      0.64      0.69      1717\n",
      "\n",
      "\n",
      "Thinking vs Feeling\n",
      "Avg AUC: 0.82, Avg Accuracy: 0.74, Avg F1: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75       929\n",
      "           1       0.70      0.75      0.72       788\n",
      "\n",
      "    accuracy                           0.74      1717\n",
      "   macro avg       0.73      0.74      0.73      1717\n",
      "weighted avg       0.74      0.74      0.74      1717\n",
      "\n",
      "\n",
      "Judging vs Perceiving\n",
      "Avg AUC: 0.65, Avg Accuracy: 0.60, Avg F1: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67      1037\n",
      "           1       0.51      0.58      0.54       680\n",
      "\n",
      "    accuracy                           0.61      1717\n",
      "   macro avg       0.60      0.61      0.60      1717\n",
      "weighted avg       0.62      0.61      0.62      1717\n",
      "\n",
      "\n",
      "Time Taken: 243.05 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# using TF-IDF vectorized data\\nrf_ct = imb_make_pipeline(\\n    preprocesser_ct,\\n    DenseTransformer(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=10),\\n)\\ncreate_model(rf_ct, X, y, nsplits=5)\";\n",
       "                var nbb_formatted_code = \"# using TF-IDF vectorized data\\nrf_ct = imb_make_pipeline(\\n    preprocesser_ct,\\n    DenseTransformer(),\\n    RandomUnderSampler(),\\n    RandomForestClassifier(n_estimators=100, max_depth=10),\\n)\\ncreate_model(rf_ct, X, y, nsplits=5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using TF-IDF vectorized data\n",
    "rf_ct = imb_make_pipeline(\n",
    "    preprocesser_ct,\n",
    "    DenseTransformer(),\n",
    "    RandomUnderSampler(),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=10),\n",
    ")\n",
    "create_model(rf_ct, X, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistics Regression using TF-IDF Vectorizer\n",
    "\n",
    "# clf_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression(),)\n",
    "# create_model(clf_tf, X_tf, y, nsplits=5)\n",
    "\n",
    "# clf_ct = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), LogisticRegression(),)\n",
    "# create_model(clf_ct, X_ct, y, nsplits=5)\n",
    "\n",
    "# nb_tf = imb_make_pipeline(MinMaxScaler(), RandomUnderSampler(), MultinomialNB())\n",
    "# create_model(nb_tf, X_tf, y, nsplits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"def create_final_model(model, X, target):\\n    \\n    # to time the individual model run time\\n    t = time.time()\\n\\n    for col in target.columns:\\n\\n        model.fit(X, target[col])\\n\\n        dump(model, f\\\"clf_{col}.joblib\\\")\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")    \";\n",
       "                var nbb_formatted_code = \"def create_final_model(model, X, target):\\n\\n    # to time the individual model run time\\n    t = time.time()\\n\\n    for col in target.columns:\\n\\n        model.fit(X, target[col])\\n\\n        dump(model, f\\\"clf_{col}.joblib\\\")\\n\\n    print(f\\\"\\\\nTime Taken: {time.time()-t:.2f} seconds\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_final_model(model, X, target):\n",
    "    \n",
    "    # to time the individual model run time\n",
    "    t = time.time()\n",
    "\n",
    "    for col in target.columns:\n",
    "\n",
    "        model.fit(X, target[col])\n",
    "\n",
    "        dump(model, f\"clf_{col}.joblib\")\n",
    "\n",
    "    print(f\"\\nTime Taken: {time.time()-t:.2f} seconds\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Taken: 32.26 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"clf_tf = imb_make_pipeline(\\n    preprocesser_tf, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\\n)\\ncreate_final_model(clf_tf, X, y)\";\n",
       "                var nbb_formatted_code = \"clf_tf = imb_make_pipeline(\\n    preprocesser_tf, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\\n)\\ncreate_final_model(clf_tf, X, y)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf_tf = imb_make_pipeline(\n",
    "    preprocesser_tf, DenseTransformer(), RandomUnderSampler(), LogisticRegression(),\n",
    ")\n",
    "create_final_model(clf_tf, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
